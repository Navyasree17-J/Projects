# -*- coding: utf-8 -*-
"""backend_models.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1hWDHBEe-B23Zsseu-ivt_MisZUlI_GTh
"""

!pip install -q ultralytics roboflow opencv-python matplotlib scikit-learn numpy tqdm

from ultralytics import YOLO
from google.colab import drive
import cv2
import numpy as np
import matplotlib.pyplot as plt

drive.mount('/content/drive')

print(" Setup completed successfully")

!ls /content/drive/MyDrive

import cv2
import numpy as np
import matplotlib.pyplot as plt
from ultralytics import YOLO
from tqdm import tqdm
from sklearn.preprocessing import MinMaxScaler

import os

BASE_PATH = "/content/drive/MyDrive/Crowd_Anomaly_Project"
os.makedirs(BASE_PATH, exist_ok=True)

paths = [
    "videos",
    "frames",
    "results",
    "models"
]

for p in paths:
    os.makedirs(os.path.join(BASE_PATH, p), exist_ok=True)

print("Project folders created successfully")

from IPython.display import display, Javascript
from google.colab.output import eval_js
from base64 import b64decode
import cv2
import matplotlib.pyplot as plt

display(Javascript('''
async function capture() {
  const div = document.createElement('div');
  const video = document.createElement('video');
  const stream = await navigator.mediaDevices.getUserMedia({ video: true });

  document.body.appendChild(div);
  div.appendChild(video);
  video.srcObject = stream;
  await video.play();

  await new Promise(resolve => setTimeout(resolve, 2000));

  const canvas = document.createElement('canvas');
  canvas.width = video.videoWidth;
  canvas.height = video.videoHeight;
  canvas.getContext('2d').drawImage(video, 0, 0);

  stream.getTracks().forEach(track => track.stop());
  div.remove();

  return canvas.toDataURL('image/jpeg', 0.8);
}
'''))

# Call JS function
image_data = eval_js('capture()')
image_bytes = b64decode(image_data.split(',')[1])

# Save image
image_path = f"{BASE_PATH}/results/test_camera.jpg"
with open(image_path, "wb") as f:
    f.write(image_bytes)

# Display image
img = cv2.imread(image_path)
plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))
plt.axis('off')

print("âœ… Laptop camera image captured successfully")

from ultralytics import YOLO

yolo_model = YOLO("yolov8n.pt")

def estimate_density(frame):
    """
    Input : Frame (live camera / dataset frame)
    Output: People count and bounding boxes
    """
    results = yolo_model(frame, conf=0.3, classes=[0])

    boxes = []
    for r in results:
        for box in r.boxes.xyxy:
            x1, y1, x2, y2 = map(int, box)
            boxes.append((x1, y1, x2-x1, y2-y1))

    return len(boxes), boxes

from IPython.display import display, Javascript
from google.colab.output import eval_js
from base64 import b64decode
import time

density_list = []
num_frames = 10

for i in range(num_frames):
    display(Javascript('''
    async function capture() {
      const video = document.createElement('video');
      const stream = await navigator.mediaDevices.getUserMedia({ video: true });
      video.srcObject = stream;
      await video.play();

      await new Promise(resolve => setTimeout(resolve, 500));

      const canvas = document.createElement('canvas');
      canvas.width = video.videoWidth;
      canvas.height = video.videoHeight;
      canvas.getContext('2d').drawImage(video, 0, 0);

      stream.getTracks().forEach(track => track.stop());
      return canvas.toDataURL('image/jpeg', 0.8);
    }
    '''))

    img_data = eval_js('capture()')
    img_bytes = b64decode(img_data.split(',')[1])

    # Decode image
    frame = cv2.imdecode(np.frombuffer(img_bytes, np.uint8), cv2.IMREAD_COLOR)

    count, boxes = estimate_density(frame)
    density_list.append(count)

    # Draw boxes
    for (x, y, w, h) in boxes:
        cv2.rectangle(frame, (x, y), (x+w, y+h), (0,255,0), 2)

    cv2.putText(frame, f"People Count: {count}", (10,30),
                cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,255), 2)

    plt.figure(figsize=(5,4))
    plt.imshow(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))
    plt.axis('off')
    plt.show()

print("Crowd density values collected from live dataset:", density_list)

def detect_stampede_risk(density_list, density_threshold=6, spike_threshold=3):
    """
    density_list       : List of people counts over time
    density_threshold  : Maximum safe crowd limit
    spike_threshold    : Sudden increase threshold
    """
    if len(density_list) < 2:
        return "INSUFFICIENT DATA"

    max_density = max(density_list)
    sudden_spike = any(
        abs(density_list[i] - density_list[i-1]) >= spike_threshold
        for i in range(1, len(density_list))
    )

    if max_density >= density_threshold or sudden_spike:
        return "HIGH STAMPEDE RISK"
    else:
        return "NORMAL CROWD"

risk_status = detect_stampede_risk(density_list)
print("ðŸš¨ Stampede Risk Status:", risk_status)

import matplotlib.pyplot as plt

plt.figure(figsize=(8,4))
plt.plot(density_list, marker='o')
plt.xlabel("Frame Number")
plt.ylabel("People Count")
plt.title("Crowd Density Trend (Live Camera Dataset)")
plt.grid(True)
plt.show()

print("========== RESULT SUMMARY ==========")
print("Dataset Used           : Live Camera Dataset")
print("People Count per Frame :", density_list)
print("Maximum Crowd Detected :", max(density_list))
print("Stampede Risk Status   :", risk_status)
print("====================================")

import pickle
import os
import json
from datetime import datetime

# ðŸ” Always re-define BASE_PATH (prevents NameError)
BASE_PATH = "/content/drive/MyDrive/Crowd_Anomaly_Project"

SAVE_PATH = os.path.join(BASE_PATH, "saved_state")
os.makedirs(SAVE_PATH, exist_ok=True)

# 1ï¸âƒ£ Save density list
with open(os.path.join(SAVE_PATH, "density_list.pkl"), "wb") as f:
    pickle.dump(density_list, f)

# 2ï¸âƒ£ Save risk status
with open(os.path.join(SAVE_PATH, "risk_status.txt"), "w") as f:
    f.write(risk_status)

# 3ï¸âƒ£ Save summary JSON
summary = {
    "timestamp": str(datetime.now()),
    "dataset": "Live Camera Dataset",
    "density_list": density_list,
    "max_density": max(density_list),
    "risk_status": risk_status
}

with open(os.path.join(SAVE_PATH, "summary.json"), "w") as f:
    json.dump(summary, f, indent=4)

print(" Crowd anomaly state saved successfully to Google Drive")

!ls /content/drive/MyDrive/Crowd_Anomaly_Project/saved_state

ABNORMAL_CLASSES = [
    "backpack",
    "handbag",
    "suitcase",
    "knife",
    "scissors",
    "sports ball"
]

print("Abnormal object classes defined")

def detect_abnormal_objects(frame, conf_threshold=0.25):
    results = abnormal_model(frame, conf=conf_threshold)

    abnormal_detections = []
    debug_detections = []

    for result in results:
        for box in result.boxes:
            cls_id = int(box.cls[0])
            cls_name = abnormal_model.names[cls_id]
            confidence = float(box.conf[0])
            x1, y1, x2, y2 = map(int, box.xyxy[0])

            debug_detections.append((cls_name, confidence, (x1,y1,x2,y2)))


            if cls_name in ABNORMAL_CLASSES:
                abnormal_detections.append({
                    "class": cls_name,
                    "confidence": confidence,
                    "bbox": (x1, y1, x2, y2)
                })

    return abnormal_detections, debug_detections

def weapon_risk_behavior(person_boxes, density):
    for (x,y,w,h) in person_boxes:
        if h > 150 and density > 5:
            return True
    return False

from IPython.display import display, Javascript
from google.colab.output import eval_js
from base64 import b64decode
import numpy as np
import cv2
import matplotlib.pyplot as plt

def capture_image_colab():
    display(Javascript("""
        async function capture() {
            const div = document.createElement('div');
            const video = document.createElement('video');
            const stream = await navigator.mediaDevices.getUserMedia({video: true});
            document.body.appendChild(div);
            div.appendChild(video);
            video.srcObject = stream;
            await video.play();
            await new Promise(resolve => setTimeout(resolve, 2000));
            const canvas = document.createElement('canvas');
            canvas.width = video.videoWidth;
            canvas.height = video.videoHeight;
            canvas.getContext('2d').drawImage(video, 0, 0);
            stream.getTracks().forEach(track => track.stop());
            div.remove();
            return canvas.toDataURL('image/jpeg');
        }
        capture();
    """))
    data = eval_js("capture()")
    binary = b64decode(data.split(',')[1])
    img = cv2.imdecode(np.frombuffer(binary, np.uint8), cv2.IMREAD_COLOR)
    return img

!pip install -q ultralytics roboflow opencv-python matplotlib

from roboflow import Roboflow

rf = Roboflow(api_key="e5iUEbNNU7ztKaKE2t36")
print("Roboflow connected successfully")

!pip install -q roboflow
from roboflow import Roboflow

rf = Roboflow(api_key="e5iUEbNNU7ztKaKE2t36")

project = rf.workspace("ahad-liwdw").project("weapon-detection-twbhu")

dataset = project.version(1).download("yolov8")

import os

!ls /content/Weapon-Detection-1
!cat /content/Weapon-Detection-1/data.yaml

import os

BASE_PATH = "/content/drive/MyDrive/Crowd_Anomaly_Project"
MODEL_PATH = os.path.join(BASE_PATH, "models")
RESULTS_PATH = os.path.join(BASE_PATH, "results")

os.makedirs(MODEL_PATH, exist_ok=True)
os.makedirs(RESULTS_PATH, exist_ok=True)

print(" Paths initialized")

weapon_model.train(
    data="/content/Weapon-Detection-1/data.yaml",
    epochs=15,
    imgsz=460,
    batch=8,
    device="cpu",
    project=MODEL_PATH,
    name="weapon_detection"
)

!ls /content

!ls /content/drive/MyDrive/Crowd_Anomaly_Project

!ls /content/drive/MyDrive/Crowd_Anomaly_Project/models

from ultralytics import YOLO

model = YOLO("yolov8n.pt")

model.train(
    data="/content/Weapon-Detection-1/data.yaml",
    epochs=5,
    imgsz=640,
    batch=8,
    device="cpu",
    project="/content",
    name="weapon_tmp"
)

!ls /content/weapon_tmp/weights

!cp /content/weapon_tmp/weights/best.pt \
/content/drive/MyDrive/Crowd_Anomaly_Project/models/yolov8n-weapon.pt

!ls /content/drive/MyDrive/Crowd_Anomaly_Project/models

from ultralytics import YOLO

weapon_model = YOLO(
    "/content/drive/MyDrive/Crowd_Anomaly_Project/models/yolov8n-weapon.pt"
)

print("Weapon model loaded successfully")

results = weapon_model.predict(
    source="/content/Weapon-Detection-1/test/images",
    conf=0.4,
    save=True
)

!ls /content/drive/MyDrive/Crowd_Anomaly_Project/models/weapon_detection



!pip install ultralytics

!ls /content

!ls /content/Weapon-Detection-1

!find /content/Weapon-Detection-1 -maxdepth 3 -type f

!rm -rf /content/Weapon-Detection-1
!ls /content

!pip install -q roboflow

from roboflow import Roboflow

rf = Roboflow(api_key="e5iUEbNNU7ztKaKE2t36")

# This uses YOUR workspace automatically
project = rf.workspace().project("weapon-detection")

dataset = project.version(1).download("yolov8")

!pip install -q roboflow

from roboflow import Roboflow

rf = Roboflow(api_key="YOUR_PRIVATE_API_KEY")

# This uses YOUR workspace automatically
project = rf.workspace().project("weapon-detection")

dataset = project.version(1).download("yolov8")

!unzip /content/Weapon-Detection-1/roboflow.zip -d /content/Weapon-Detection-1

!find /content/Weapon-Detection-1 -name data.yaml

from ultralytics import YOLO

model = YOLO("yolov8n.pt")

model.train(
    data=dataset.location + "/data.yaml",
    epochs=20,
    imgsz=416,
    batch=8,
    device=cpu,
    workers=2,
    name="weapon_train"
)

!ls /content/runs/detect



model.predict(
    source="/content/weapon-detection-1/test/images",
    conf=0.5,
    save=True
)

frame = capture_image_colab()

abnormal_detections, debug_detections = detect_abnormal_objects(frame)

print("Total detected objects:", len(debug_detections))
print("Abnormal objects detected:", len(abnormal_detections))

for cls, conf, (x1,y1,x2,y2) in debug_detections:
    cv2.rectangle(frame, (x1,y1), (x2,y2), (0, 255, 0), 2)
    cv2.putText(frame, f"{cls}", (x1, y1-8),
                cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,255,0), 2)

for det in abnormal_detections:
    x1, y1, x2, y2 = det["bbox"]
    cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 0, 255), 3)
    cv2.putText(frame, f"ABNORMAL: {det['class']}",
                (x1, y1 - 10),
                cv2.FONT_HERSHEY_SIMPLEX,
                0.6,
                (0, 0, 255),
                2)

plt.figure(figsize=(8,6))
plt.imshow(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))
plt.axis("off")